{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose** of this project is to conduct exploratory data analysis on a provided data set. Our mission is to continue the investigation we began in 'preliminary_data_analysis' and perform further EDA on this data with the aim of learning more about the variables. Of particular interest is information related to what distinguishes claim videos from opinion videos.\n",
    "\n",
    "**The goal** is to explore the dataset and create visualizations.\n",
    "<br/>\n",
    "*This activity has 4 parts:*\n",
    "\n",
    "**Part 1:** Imports, links, and loading\n",
    "\n",
    "**Part 2:** Data Exploration\n",
    "*   Data cleaning\n",
    "\n",
    "\n",
    "**Part 3:** Build visualizations\n",
    "\n",
    "**Part 4:** Evaluate and share results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACE: Plan\n",
    "\n",
    "1. Identify any outliers:\n",
    "\n",
    "**Exemplar response:**\n",
    "\n",
    "\n",
    "*   What methods are best for identifying outliers?\n",
    "  * Use numpy functions to investigate the `mean()` and `median()` of the data and understand range of data values\n",
    "  * Use a boxplot to visualize the distribution of the data\n",
    "*   How do you make the decision to keep or exclude outliers from any future models?\n",
    "  * There are three main options for dealing with outliers: keeping them as they are, deleting them, or reassigning them. Whether you keep outliers as they are, delete them, or reassign values is a decision that you make on a dataset-by-dataset basis, according to what your goals are for the model you are planning to construct. To help you make the decision, you can start with these general guidelines:\n",
    "\n",
    "      * Delete them: If you are sure the outliers are mistakes, typos, or errors and the dataset will be used for modeling or machine learning, then you are more likely to decide to delete outliers. Of the three choices, youâ€™ll use this one the least.\n",
    "      * Reassign them: If the dataset is small and/or the data will be used for modeling or machine learning, you are more likely to choose a path of deriving new values to replace the outlier values.\n",
    "      * Leave them: For a dataset that you plan to do EDA/analysis on and nothing else, or for a dataset you are preparing for a model that is resistant to outliers, it is most likely that you are going to leave them in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import packages for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "data = pd.read_csv(\"tiktok_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACE: Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and examine the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the data\n",
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a table of descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACE: Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_duration_sec`\n",
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_duration_sec')\n",
    "sns.boxplot(x=data['video_duration_sec']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_duration_sec'], bins=range(0,61,5))\n",
    "plt.title('Video duration histogram');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_view_count`\n",
    "plt.figure(figsize=(5, 1))\n",
    "plt.title('video_view_count')\n",
    "sns.boxplot(x=data['video_view_count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_view_count'], bins=range(0,(10**6+1),10**5))\n",
    "plt.title('Video view count histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_like_count`\n",
    "plt.figure(figsize=(10,1))\n",
    "plt.title('video_like_count')\n",
    "sns.boxplot(x=data['video_like_count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,3))\n",
    "ax = sns.histplot(data['video_like_count'], bins=range(0,(7*10**5+1),10**5))\n",
    "labels = [0] + [str(i) + 'k' for i in range(100, 701, 100)]\n",
    "ax.set_xticks(range(0,7*10**5+1,10**5), labels=labels)\n",
    "plt.title('Video like count histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_comment_count`\n",
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_comment_count')\n",
    "sns.boxplot(x=data['video_comment_count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_comment_count'], bins=range(0,(3001),100))\n",
    "plt.title('Video comment count histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_share_count`\n",
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_share_count')\n",
    "sns.boxplot(x=data['video_share_count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_share_count'], bins=range(0,(270001),10000))\n",
    "plt.title('Video share count histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_download_count`\n",
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_download_count')\n",
    "sns.boxplot(x=data['video_download_count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_download_count'], bins=range(0,(15001),500))\n",
    "plt.title('Video download count histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m7\u001b[39m,\u001b[39m4\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m sns\u001b[39m.\u001b[39mhistplot(data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m              x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclaim_status\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m              hue\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mverified_status\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m              multiple\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdodge\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m              shrink\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mClaims by verification status histogram\u001b[39m\u001b[39m'\u001b[39m);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# claims status by verification status\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data=data,\n",
    "             x='claim_status',\n",
    "             hue='verified_status',\n",
    "             multiple='dodge',\n",
    "             shrink=0.9)\n",
    "plt.title('Claims by verification status histogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim status by author ban status\n",
    "fig = plt.figure(figsize=(7,4))\n",
    "sns.histplot(data, x='claim_status', hue='author_ban_status',\n",
    "             multiple='dodge',\n",
    "             hue_order=['active', 'under review', 'banned'],\n",
    "             shrink=0.9,\n",
    "             palette={'active':'green', 'under review':'orange', 'banned':'red'},\n",
    "             alpha=0.5)\n",
    "plt.title('Claim status by author ban status - counts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median view counts by ban status\n",
    "ban_status_counts = data.groupby(['author_ban_status']).median(\n",
    "    numeric_only=True).reset_index()\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "sns.barplot(data=ban_status_counts,\n",
    "            x='author_ban_status',\n",
    "            y='video_view_count',\n",
    "            order=['active', 'under review', 'banned'],\n",
    "            palette={'active':'green', 'under review':'orange', 'banned':'red'},\n",
    "            alpha=0.5)\n",
    "plt.title('Median view count by ban status');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('claim_status')['video_view_count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total views by claim status\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "plt.pie(data.groupby('claim_status')['video_view_count'].sum(), labels=['claim', 'opinion'])\n",
    "plt.title('Total views by video claim status');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 4. Determine outliers**\n",
    "\n",
    "When building predictive models, the presence of outliers can be problematic. For example, if you were trying to predict the view count of a particular video, videos with extremely high view counts might introduce bias to a model. Also, some outliers might indicate problems with how data was captured or recorded.\n",
    "\n",
    "The ultimate objective of the TikTok project is to build a model that predicts whether a video is a claim or opinion. The analysis you've performed indicates that a video's engagement level is strongly correlated with its claim status. There's no reason to believe that any of the values in the TikTok data are erroneously captured, and they align with expectation of how social media works: a very small proportion of videos get super high engagement levels. That's the nature of viral content.\n",
    "\n",
    "Nonetheless, it's good practice to get a sense of just how many of your data points could be considered outliers. The definition of an outlier can change based on the details of your project, and it helps to have domain expertise to decide a threshold. You've learned that a common way to determine outliers in a normal distribution is to calculate the interquartile range (IQR) and set a threshold that is 1.5 * IQR above the 3rd quartile.\n",
    "\n",
    "In this TikTok dataset, the values for the count variables are not normally distributed. They are heavily skewed to the right. One way of modifying the outlier threshold is by calculating the **median** value for each variable and then adding 1.5 * IQR. This results in a threshold that is, in this case, much lower than it would be if you used the 3rd quartile.\n",
    "\n",
    "Write a for loop that iterates over the column names of each count variable. For each iteration:\n",
    "1. Calculate the IQR of the column\n",
    "2. Calculate the median of the column\n",
    "3. Calculate the outlier threshold (median + 1.5 * IQR)\n",
    "4. Calculate the numer of videos with a count in that column that exceeds the outlier threshold\n",
    "5. Print \"Number of outliers, {column name}: {outlier count}\"\n",
    "\n",
    "```\n",
    "Example:\n",
    "Number of outliers, video_view_count: ___\n",
    "Number of outliers, video_like_count: ___\n",
    "Number of outliers, video_share_count: ___\n",
    "Number of outliers, video_download_count: ___\n",
    "Number of outliers, video_comment_count: ___\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = ['video_view_count',\n",
    "              'video_like_count',\n",
    "              'video_share_count',\n",
    "              'video_download_count',\n",
    "              'video_comment_count',\n",
    "              ]\n",
    "\n",
    "for column in count_cols:\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    median = data[column].median()\n",
    "    outlier_threshold = median + 1.5*iqr\n",
    "\n",
    "    # Count the number of values that exceed the outlier threshold\n",
    "    outlier_count = (data[column] > outlier_threshold).sum()\n",
    "    print(f'Number of outliers, {column}:', outlier_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of `video_view_count` versus `video_like_count` according to 'claim_status'\n",
    "sns.scatterplot(x=data[\"video_view_count\"], y=data[\"video_like_count\"],\n",
    "                hue=data[\"claim_status\"], s=10, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of `video_view_count` versus `video_like_count` for opinions only\n",
    "opinion = data[data['claim_status']=='opinion']\n",
    "sns.scatterplot(x=opinion[\"video_view_count\"], y=opinion[\"video_like_count\"],\n",
    "                 s=10, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACE: Execute\n",
    "\n",
    "I have learned ....\n",
    "\n",
    "* *I examined the data distribution/spread, count frequencies, mean and median values, extreme values/outliers, missing data, and more. I analyzed correlations between variables, particularly between the claim_status variable and others.*\n",
    "\n",
    "My other questions are ....\n",
    "\n",
    "* *I want to further investigate distinctive characteristics that apply only to claims or only to opinions. Also, I want to consider other variables that might be helpful in understanding the data.*\n",
    "\n",
    "My client would likely want to know ...\n",
    "\n",
    "* *My client would want to know the assumptions regarding what data might be predictive of claim_status.*\n",
    "\n",
    "\n",
    "EDA is important because ...\n",
    "\n",
    "* *EDA helps a data professional to get to know the data, understand its outliers, clean its missing values, and prepare it for future modeling.*\n",
    "\n",
    "Visualizations helped me understand ..\n",
    "\n",
    "* *That we will need to make decisions on certain considerations prior to designing a model. (for example, what to do with outliers, duplicate values, or missing data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
